(*
 * Model.zpp - Parameter Shapes and Forward/Sampling Contracts
 * Z++ Formal Specification for Deltecho Model Package
 * 
 * Defines the formal contracts for model parameters, forward pass,
 * attention computation, and sampling strategies.
 *)

SCHEMA Model
IMPORTS Types, ModelConfig

(* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   SECTION 1: Parameter Shape Types
   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• *)

TYPE EmbeddingParams == âŸ¦
    weight: Tensor2D[VocabSize, EmbedDim]
âŸ§

TYPE AttentionParams == âŸ¦
    q_proj: Tensor2D[HiddenDim, HiddenDim],
    k_proj: Tensor2D[HiddenDim, HiddenDim],
    v_proj: Tensor2D[HiddenDim, HiddenDim],
    o_proj: Tensor2D[HiddenDim, HiddenDim],
    
    (* Optional biases *)
    q_bias: optional Tensor1D[HiddenDim],
    k_bias: optional Tensor1D[HiddenDim],
    v_bias: optional Tensor1D[HiddenDim],
    o_bias: optional Tensor1D[HiddenDim]
âŸ§

TYPE FFNParams == âŸ¦
    gate_proj: Tensor2D[HiddenDim, â„•â‚],      (* Hidden â†’ Intermediate *)
    up_proj: Tensor2D[HiddenDim, â„•â‚],        (* Hidden â†’ Intermediate *)
    down_proj: Tensor2D[â„•â‚, HiddenDim],      (* Intermediate â†’ Hidden *)
    
    (* Optional biases *)
    gate_bias: optional Tensor1D[â„•â‚],
    up_bias: optional Tensor1D[â„•â‚],
    down_bias: optional Tensor1D[HiddenDim]
âŸ§

TYPE NormParams == âŸ¦
    weight: Tensor1D[HiddenDim],
    bias: optional Tensor1D[HiddenDim]
âŸ§

TYPE TransformerLayerParams == âŸ¦
    input_layernorm: NormParams,
    self_attn: AttentionParams,
    post_attention_layernorm: NormParams,
    mlp: FFNParams
âŸ§

TYPE CognitiveStreamParams == âŸ¦
    stream_embedding: Tensor2D[COGNITIVE_STREAMS, HiddenDim],
    step_embedding: Tensor2D[COGNITIVE_STEPS, HiddenDim],
    cross_stream_attn: AttentionParams,
    stream_gate: Tensor2D[HiddenDim, HiddenDim]
âŸ§

TYPE LMHeadParams == âŸ¦
    weight: Tensor2D[HiddenDim, VocabSize],
    bias: optional Tensor1D[VocabSize]
âŸ§

(* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   SECTION 2: Complete Model Parameters
   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• *)

TYPE ModelParams == âŸ¦
    (* Embeddings *)
    embed_tokens: EmbeddingParams,
    
    (* Transformer layers *)
    layers: seq TransformerLayerParams,
    
    (* Final normalization *)
    norm: NormParams,
    
    (* Language model head *)
    lm_head: LMHeadParams,
    
    (* Cognitive architecture *)
    cognitive: optional CognitiveStreamParams,
    
    (* Rotary embeddings (precomputed) *)
    rotary_emb: optional âŸ¦
        cos_cached: Tensor2D[SeqLen, â„•â‚],
        sin_cached: Tensor2D[SeqLen, â„•â‚]
    âŸ§
âŸ§

(* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   SECTION 3: Model State
   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• *)

TYPE KVCache == âŸ¦
    key_cache: seq Tensor3D[BatchSize, SeqLen, HiddenDim],
    value_cache: seq Tensor3D[BatchSize, SeqLen, HiddenDim],
    seen_tokens: â„•
âŸ§

TYPE CognitiveState == âŸ¦
    stream_states: seq StreamState,
    current_stream: StreamId,
    current_step: StepId,
    stream_hidden: Tensor2D[COGNITIVE_STREAMS, HiddenDim]
âŸ§

STATE ModelState == âŸ¦
    config: ModelConfigState,
    params: ModelParams,
    kv_cache: optional KVCache,
    cognitive_state: optional CognitiveState,
    
    (* Training state *)
    is_training: ğ”¹,
    gradient_checkpointing: ğ”¹
âŸ§

(* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   SECTION 4: Forward Pass Types
   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• *)

TYPE ModelInput == âŸ¦
    input_ids: Tensor2D[BatchSize, SeqLen],
    attention_mask: optional Tensor2D[BatchSize, SeqLen],
    position_ids: optional Tensor2D[BatchSize, SeqLen],
    past_key_values: optional KVCache,
    inputs_embeds: optional Tensor3D[BatchSize, SeqLen, HiddenDim],
    use_cache: ğ”¹,
    output_attentions: ğ”¹,
    output_hidden_states: ğ”¹,
    
    (* Cognitive inputs *)
    stream_ids: optional Tensor1D[BatchSize],
    step_ids: optional Tensor1D[BatchSize]
âŸ§

TYPE ModelOutput == âŸ¦
    logits: Tensor3D[BatchSize, SeqLen, VocabSize],
    past_key_values: optional KVCache,
    hidden_states: optional seq Tensor3D[BatchSize, SeqLen, HiddenDim],
    attentions: optional seq Tensor3D[BatchSize, NumHeads, SeqLen, SeqLen],
    
    (* Cognitive outputs *)
    stream_outputs: optional seq Tensor3D[BatchSize, SeqLen, HiddenDim],
    cognitive_attention: optional Tensor3D[COGNITIVE_STREAMS, SeqLen, SeqLen]
âŸ§

TYPE LossOutput == âŸ¦
    loss: â„,
    logits: Tensor3D[BatchSize, SeqLen, VocabSize],
    past_key_values: optional KVCache
âŸ§

(* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   SECTION 5: Invariant Predicates
   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• *)

PRED ValidModelParams(p: ModelParams, c: ModelConfigState) â‰œ
    (* Embedding dimensions *)
    dimâ‚(p.embed_tokens.weight) = c.vocab_size âˆ§
    dimâ‚‚(p.embed_tokens.weight) = c.hidden_size âˆ§
    
    (* Number of layers *)
    #p.layers = c.num_hidden_layers âˆ§
    
    (* Each layer has correct dimensions *)
    (âˆ€ layer âˆˆ ran p.layers â€¢
        dimâ‚(layer.self_attn.q_proj) = c.hidden_size âˆ§
        dimâ‚‚(layer.self_attn.q_proj) = c.hidden_size âˆ§
        dimâ‚(layer.mlp.gate_proj) = c.hidden_size âˆ§
        dimâ‚‚(layer.mlp.gate_proj) = c.ffn.intermediate_size) âˆ§
    
    (* LM head dimensions *)
    dimâ‚(p.lm_head.weight) = c.hidden_size âˆ§
    dimâ‚‚(p.lm_head.weight) = c.vocab_size âˆ§
    
    (* Cognitive params if enabled *)
    (c.cognitive.memory_attention â‡’ p.cognitive â‰  âŠ¥)

PRED ValidKVCache(cache: KVCache, c: ModelConfigState) â‰œ
    #cache.key_cache = c.num_hidden_layers âˆ§
    #cache.value_cache = c.num_hidden_layers âˆ§
    cache.seen_tokens â‰¤ c.max_position_embeddings

PRED ValidModelInput(input: ModelInput, c: ModelConfigState) â‰œ
    (* Input IDs within vocabulary *)
    (âˆ€ i: 1..dimâ‚(input.input_ids); j: 1..dimâ‚‚(input.input_ids) â€¢
        input.input_ids[i][j] < c.vocab_size) âˆ§
    
    (* Attention mask matches input shape *)
    (input.attention_mask â‰  âŠ¥ â‡’
        dimâ‚(input.attention_mask!) = dimâ‚(input.input_ids) âˆ§
        dimâ‚‚(input.attention_mask!) = dimâ‚‚(input.input_ids)) âˆ§
    
    (* Position IDs within bounds *)
    (input.position_ids â‰  âŠ¥ â‡’
        âˆ€ i: 1..dimâ‚(input.position_ids!); j: 1..dimâ‚‚(input.position_ids!) â€¢
            input.position_ids![i][j] < c.max_position_embeddings) âˆ§
    
    (* Cognitive inputs valid *)
    (input.stream_ids â‰  âŠ¥ â‡’
        âˆ€ s âˆˆ ran input.stream_ids! â€¢ 1 â‰¤ s â‰¤ COGNITIVE_STREAMS) âˆ§
    (input.step_ids â‰  âŠ¥ â‡’
        âˆ€ s âˆˆ ran input.step_ids! â€¢ 1 â‰¤ s â‰¤ COGNITIVE_STEPS)

PRED ValidModelOutput(output: ModelOutput, input: ModelInput, c: ModelConfigState) â‰œ
    (* Logits shape *)
    dimâ‚(output.logits) = dimâ‚(input.input_ids) âˆ§
    dimâ‚‚(output.logits) = dimâ‚‚(input.input_ids) âˆ§
    dimâ‚ƒ(output.logits) = c.vocab_size âˆ§
    
    (* Hidden states if requested *)
    (input.output_hidden_states â‡’
        output.hidden_states â‰  âŠ¥ âˆ§
        #output.hidden_states! = c.num_hidden_layers + 1) âˆ§
    
    (* Attentions if requested *)
    (input.output_attentions â‡’
        output.attentions â‰  âŠ¥ âˆ§
        #output.attentions! = c.num_hidden_layers)

(* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   SECTION 6: State Invariants
   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• *)

INVARIANT ModelStateInvariant
    âˆ€ state: ModelState â€¢
        ValidModelParams(state.params, state.config) âˆ§
        (state.kv_cache â‰  âŠ¥ â‡’ ValidKVCache(state.kv_cache!, state.config)) âˆ§
        (state.cognitive_state â‰  âŠ¥ â‡’
            #state.cognitive_state!.stream_states = COGNITIVE_STREAMS âˆ§
            1 â‰¤ state.cognitive_state!.current_stream â‰¤ COGNITIVE_STREAMS âˆ§
            1 â‰¤ state.cognitive_state!.current_step â‰¤ COGNITIVE_STEPS)

(* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   SECTION 7: Forward Pass Operations
   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• *)

OP Forward
    Î”STATE ModelState
    input?: ModelInput
    output!: ModelOutput
    
    PRE 
        ValidModelInput(input?, config) âˆ§
        Â¬is_training
    POST
        ValidModelOutput(output!, input?, config) âˆ§
        
        (* KV cache updated if used *)
        (input?.use_cache â‡’ 
            kv_cache' â‰  âŠ¥ âˆ§
            kv_cache'!.seen_tokens = 
                (IF input?.past_key_values â‰  âŠ¥ 
                 THEN input?.past_key_values!.seen_tokens 
                 ELSE 0) + dimâ‚‚(input?.input_ids)) âˆ§
        
        (* Cognitive state updated if enabled *)
        (cognitive_state â‰  âŠ¥ âˆ§ input?.stream_ids â‰  âŠ¥ â‡’
            cognitive_state'!.current_step = 
                ((cognitive_state!.current_step - 1 + 1) mod COGNITIVE_STEPS) + 1)

OP ForwardWithLoss
    Î”STATE ModelState
    input?: ModelInput
    labels?: Tensor2D[BatchSize, SeqLen]
    output!: LossOutput
    
    PRE 
        ValidModelInput(input?, config) âˆ§
        dimâ‚(labels?) = dimâ‚(input?.input_ids) âˆ§
        dimâ‚‚(labels?) = dimâ‚‚(input?.input_ids) âˆ§
        (âˆ€ i: 1..dimâ‚(labels?); j: 1..dimâ‚‚(labels?) â€¢
            labels?[i][j] < config.vocab_size âˆ¨ labels?[i][j] = -100)
    POST
        output!.loss â‰¥ 0 âˆ§
        dimâ‚(output!.logits) = dimâ‚(input?.input_ids) âˆ§
        dimâ‚‚(output!.logits) = dimâ‚‚(input?.input_ids) âˆ§
        dimâ‚ƒ(output!.logits) = config.vocab_size

(* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   SECTION 8: Attention Operations
   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• *)

OP ComputeAttention
    ÎSTATE ModelState
    query?: Tensor3D[BatchSize, SeqLen, HiddenDim]
    key?: Tensor3D[BatchSize, SeqLen, HiddenDim]
    value?: Tensor3D[BatchSize, SeqLen, HiddenDim]
    attention_mask?: optional Tensor2D[BatchSize, SeqLen]
    output!: Tensor3D[BatchSize, SeqLen, HiddenDim]
    attention_weights!: optional Tensor3D[BatchSize, NumHeads, SeqLen, SeqLen]
    
    PRE 
        dimâ‚(query?) = dimâ‚(key?) âˆ§
        dimâ‚(query?) = dimâ‚(value?) âˆ§
        dimâ‚‚(query?) = dimâ‚‚(key?) âˆ§
        dimâ‚‚(query?) = dimâ‚‚(value?) âˆ§
        dimâ‚ƒ(query?) = config.hidden_size
    POST
        dimâ‚(output!) = dimâ‚(query?) âˆ§
        dimâ‚‚(output!) = dimâ‚‚(query?) âˆ§
        dimâ‚ƒ(output!) = config.hidden_size âˆ§
        
        (* Attention weights are valid probabilities *)
        (attention_weights! â‰  âŠ¥ â‡’
            âˆ€ b: 1..dimâ‚(attention_weights!!); 
              h: 1..dimâ‚‚(attention_weights!!);
              i: 1..dimâ‚ƒ(attention_weights!!) â€¢
                Î£â±¼ attention_weights!![b][h][i][j] = 1.0)

OP ComputeCrossStreamAttention
    Î”STATE ModelState
    stream_hidden?: Tensor2D[COGNITIVE_STREAMS, HiddenDim]
    output!: Tensor2D[COGNITIVE_STREAMS, HiddenDim]
    
    PRE 
        cognitive_state â‰  âŠ¥ âˆ§
        dimâ‚(stream_hidden?) = COGNITIVE_STREAMS âˆ§
        dimâ‚‚(stream_hidden?) = config.cognitive.stream_hidden_dim
    POST
        dimâ‚(output!) = COGNITIVE_STREAMS âˆ§
        dimâ‚‚(output!) = config.cognitive.stream_hidden_dim âˆ§
        cognitive_state'!.stream_hidden = output!

(* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   SECTION 9: Sampling Operations
   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• *)

TYPE SamplingConfig == âŸ¦
    temperature: Temperature,
    top_k: optional â„•â‚,
    top_p: optional Probability,
    repetition_penalty: optional â„,
    do_sample: ğ”¹,
    num_beams: â„•â‚,
    max_new_tokens: â„•â‚,
    min_new_tokens: optional â„•,
    eos_token_id: TokenId,
    pad_token_id: TokenId
âŸ§

OP SampleNextToken
    ÎSTATE ModelState
    logits?: Tensor2D[BatchSize, VocabSize]
    sampling_config?: SamplingConfig
    past_tokens?: optional seq TokenSequence
    next_token!: Tensor1D[BatchSize]
    
    PRE 
        dimâ‚‚(logits?) = config.vocab_size âˆ§
        sampling_config?.temperature > 0
    POST
        (* All sampled tokens are valid *)
        âˆ€ t âˆˆ ran next_token! â€¢ t < config.vocab_size âˆ§
        
        (* Greedy if not sampling *)
        (Â¬sampling_config?.do_sample â‡’
            âˆ€ b: 1..dimâ‚(logits?) â€¢
                next_token![b] = argmax(logits?[b]))

OP ApplyTemperature
    logits?: Tensor2D[BatchSize, VocabSize]
    temperature?: Temperature
    output!: Tensor2D[BatchSize, VocabSize]
    
    PRE temperature? > 0
    POST 
        âˆ€ b: 1..dimâ‚(logits?); v: 1..dimâ‚‚(logits?) â€¢
            output![b][v] = logits?[b][v] / temperature?

OP ApplyTopK
    logits?: Tensor2D[BatchSize, VocabSize]
    k?: â„•â‚
    output!: Tensor2D[BatchSize, VocabSize]
    
    PRE k? > 0 âˆ§ k? â‰¤ dimâ‚‚(logits?)
    POST 
        (* Only top-k logits remain, rest are -âˆ *)
        âˆ€ b: 1..dimâ‚(logits?) â€¢
            #{v: 1..dimâ‚‚(output!) | output![b][v] > -âˆ} â‰¤ k?

OP ApplyTopP
    probs?: Tensor2D[BatchSize, VocabSize]
    p?: Probability
    output!: Tensor2D[BatchSize, VocabSize]
    
    PRE 
        0 < p? â‰¤ 1 âˆ§
        (* Input must be valid probability distribution *)
        âˆ€ b: 1..dimâ‚(probs?) â€¢ Î£áµ¥ probs?[b][v] â‰ˆ 1.0
    POST 
        (* Cumulative probability of kept tokens â‰¥ p *)
        âˆ€ b: 1..dimâ‚(output!) â€¢
            Î£{v: 1..dimâ‚‚(output!) | output![b][v] > 0} output![b][v] â‰¥ p?

OP ApplyRepetitionPenalty
    logits?: Tensor2D[BatchSize, VocabSize]
    past_tokens?: seq TokenSequence
    penalty?: â„
    output!: Tensor2D[BatchSize, VocabSize]
    
    PRE penalty? > 0
    POST 
        (* Tokens in past_tokens have reduced logits *)
        âˆ€ b: 1..dimâ‚(logits?); t âˆˆ ran past_tokens?[b] â€¢
            output![b][t] â‰¤ logits?[b][t]

(* â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   SECTION 10: Theorems and Properties
   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• *)

THEOREM AttentionNormalization:
    âˆ€ weights: Tensor3D[BatchSize, NumHeads, SeqLen, SeqLen] â€¢
        (* Attention weights sum to 1 along last dimension *)
        âˆ€ b, h, i â€¢ Î£â±¼ weights[b][h][i][j] = 1.0

THEOREM LogitsDimensionPreservation:
    âˆ€ input: ModelInput; output: ModelOutput; state: ModelState â€¢
        ValidModelInput(input, state.config) âˆ§
        ValidModelOutput(output, input, state.config) â‡’
        dimâ‚(output.logits) = dimâ‚(input.input_ids) âˆ§
        dimâ‚‚(output.logits) = dimâ‚‚(input.input_ids)

THEOREM CausalMasking:
    âˆ€ weights: Tensor3D[BatchSize, NumHeads, SeqLen, SeqLen] â€¢
        (* No attention to future positions *)
        âˆ€ b, h, i, j â€¢ j > i â‡’ weights[b][h][i][j] = 0

THEOREM CognitiveStreamPhasing:
    âˆ€ state: CognitiveState â€¢
        (* Streams are phased PHASE_OFFSET apart *)
        âˆ€ sâ‚, sâ‚‚: StreamId â€¢ sâ‚ â‰  sâ‚‚ â‡’
            |state.stream_states[sâ‚].current_step - 
             state.stream_states[sâ‚‚].current_step| mod PHASE_OFFSET = 0

END Model
